# ðŸ›¡ï¸ AI Security Weekly â€” Issue #8
**Thursday, February 19, 2026**

> *Covering the intersection of AI systems and security: vulnerabilities, tooling, research, and the arms race nobody asked for.*

---

## ðŸ”¥ This Week's Top Story

### AI Goes C2: Copilot and Grok Turned Into Covert Malware Relays

Check Point Research dropped a consequential finding this week: **AI assistants with web-browsing and URL-fetching capabilities can be abused as covert command-and-control (C2) relays** â€” and they've demonstrated it against Microsoft Copilot and xAI Grok.

The technique, dubbed **"AI as a C2 Proxy"**, works by having malware communicate with attacker-controlled URLs through the AI assistant's browsing/summarization feature. Because AI service domains are routinely allow-listed in enterprise environments, the traffic blends seamlessly into normal corporate egress. No suspicious C2 IP. No unusual protocol. Just a chatbot fetching URLs.

Worse: it's not just a relay. The same mechanism enables **AI-assisted malware operations** â€” reconnaissance workflows, scripted attacker actions, and real-time adaptive decisions ("what to do next") based on environmental feedback from the compromised host. This is the shift from AI helping write malware to AI *being part of the malware's runtime*.

> **Why it matters:** Enterprise security teams have broadly allow-listed AI platforms as trusted business tools. That trust is now a threat vector. Behavioral detection, not domain-based allow-listing, is the only durable defense.

ðŸ”— [Check Point Research: AI in the Middle](https://research.checkpoint.com/2026/ai-in-the-middle-turning-web-based-ai-services-into-c2-proxies-the-future-of-ai-driven-attacks/) | [The Hacker News](https://thehackernews.com/2026/02/researchers-show-copilot-and-grok-can.html) | [BleepingComputer](https://www.bleepingcomputer.com/news/security/ai-platforms-can-be-abused-for-stealthy-malware-communication/) | [CSO Online](https://www.csoonline.com/article/4134419/hackers-can-turn-grok-copilot-into-covert-command-and-control-channels-researchers-warn.html)

---

## ðŸ§¨ Vulnerability Roundup

### 128M VS Code Installs Exposed â€” Four Extensions, Multiple Critical CVEs

OX Security researchers disclosed critical vulnerabilities in **four widely-used VS Code extensions** with a combined install count exceeding 128 million:

| Extension | CVE | CVSS | Impact | Status |
|-----------|-----|------|--------|--------|
| Live Server | CVE-2025-65717 | 9.1 | Local file exfiltration via malicious webpage | **Unpatched** |
| Markdown Preview Enhanced | CVE-2025-65716 | 8.8 | Arbitrary JS execution via crafted .md file | **Unpatched** |
| Code Runner | CVE-2025-65715 | 7.8 | RCE | Patched |
| Microsoft Live Preview | CVE-2025-65714 | â€” | File theft | Patched |

The attack vector for Live Server (CVSS 9.1) is especially nasty: trick a developer into visiting a malicious webpage while the extension is running, and JavaScript in that page crawls the local dev server at `localhost:5500`, exfiltrating files to an attacker-controlled domain. No install required â€” just one click on a link.

> **Key quote (OX Security):** "A hacker needs only one malicious extension, or a single vulnerability within one extension, to perform lateral movement and compromise entire organizations."

**Action:** Disable Live Server and Markdown Preview Enhanced until patches land. Review extension audit policies.

ðŸ”— [The Hacker News](https://thehackernews.com/2026/02/critical-flaws-found-in-four-vs-code.html) | [CSO Online](https://www.csoonline.com/article/4133800/flaws-in-four-popular-vs-code-extensions-left-128-million-installs-open-to-attack.html) | [BleepingComputer](https://www.bleepingcomputer.com/news/security/flaws-in-popular-vscode-extensions-expose-developers-to-attacks/) | [OX Security Advisories](https://www.ox.security/blog/)

---

### Cloudflare Agents: XSS in AI Playground OAuth Callback (CVE-2026-1721)

The OAuth callback handler in Cloudflare's AI Playground (`agents` npm package) directly interpolated the `error_description` query parameter into an inline `<script>` tag â€” textbook reflected XSS. Exploiting it lets attackers **steal all user chat message history and LLM interaction logs** from the victim's session.

**Impact:** Anyone using Cloudflare's agent framework who visited a crafted OAuth error URL was exposed. Patch your `agents` dependency.

ðŸ”— [GitLab Advisory](https://advisories.gitlab.com/pkg/npm/agents/CVE-2026-1721/)

---

## ðŸŽ¯ Attacks & Research

### CRESCENTHARVEST: Iranian Protest Supporters Targeted With RAT

Acronis Threat Research Unit (TRU) disclosed **CRESCENTHARVEST**, an active espionage campaign targeting supporters of Iran's ongoing protests. Active since at least January 9, 2026, the campaign delivers a full-featured remote access trojan (RAT) designed for long-term information theft and surveillance.

Confirmed targets include diaspora communities and activist networks. The campaign is geopolitically timed â€” attacks spiked alongside protest activity â€” and the RAT has persistent access capabilities consistent with state-sponsored intent.

ðŸ”— [The Hacker News](https://thehackernews.com/2026/02/crescentharvest-campaign-targets-iran.html) | [The National](https://www.thenationalnews.com/future/technology/2026/02/17/iran-malware-crescent-harvest-cyber/) | [GBHackers](https://gbhackers.com/crescentharvest-malware-campaign/)

---

### 30+ Fake AI Chrome Extensions: 300K Users, Credentials Stolen

A cluster of 30+ malicious Chrome extensions masquerading as AI assistants has been installed by over **300,000 users**. The extensions silently steal:

- API keys (OpenAI, Anthropic, etc.)
- Email content
- Browsing history and session cookies

The social engineering hook is straightforward: users searching for AI productivity tools land on look-alike extensions with convincing names and ratings. Once installed, they operate normally while exfiltrating in the background.

> **The lesson:** "Download an AI assistant" is the new "download a free PDF converter." Browser extension supply chain hygiene is now an AI security problem.

ðŸ”— [BleepingComputer](https://www.bleepingcomputer.com/news/security/fake-ai-chrome-extensions-with-300k-users-steal-credentials-emails/) | [The Register](https://www.theregister.com/2026/02/12/30_chrome_extensions_ai)

---

### Promptware Kill Chain: A Framework for AI-Powered Malware

Researchers proposed the **"Promptware Kill Chain"** â€” a 7-stage framework specifically for AI-powered malware attacks, analogous to Lockheed Martin's cyber kill chain but adapted for LLM-enabled intrusions:

1. **Reconnaissance** â€” AI-assisted target profiling
2. **Weaponization** â€” Prompt engineering for payload generation
3. **Delivery** â€” AI-crafted phishing/social engineering
4. **Exploitation** â€” Prompt injection / AI C2 relay
5. **Installation** â€” AI-adapted persistence mechanisms
6. **C2** â€” Prompt-driven adaptive command execution
7. **Actions on Objectives** â€” AI-prioritized data exfiltration

The framework gives defenders a structured way to think about AI-native threat actors â€” and highlights where traditional kill chain defenses fall short.

ðŸ”— [News4Hackers](http://www.news4hackers.com/unlocking-ai-llm-vulnerabilities-a-comprehensive-guide-to-the-promptware-kill-chain-framework/)

---

## ðŸŒ Policy & Industry

### Google at Munich Security Conference: "AI Is Sharpening Attacker Tactics"

At the **62nd Munich Security Conference (MSC 2026)**, Google's Kent Walker and the Google Threat Intelligence Group presented findings from their AI Threat Tracker. Key points:

- Nation-state threat actors are using AI models (including Gemini, abused via jailbreak or direct API access) to automate reconnaissance, generate hyper-realistic phishing kits, and stage malware
- The EU Cybersecurity Agency (ENISA) director Juhan Lepassaar called for a full defensive rethink: "We need a rethink" â€” not an upgrade
- MSC 2026's security consensus: **fragmented AI governance + isolated defenses = systemic failure**

Google simultaneously published its **2026 Responsible AI Progress Report**, detailing internal safety measures and red-teaming investments â€” a useful contrast to the threat intelligence painting of what attackers are already doing.

ðŸ”— [Google MSC Recap](https://blog.google/innovation-and-ai/technology/safety-security/resilience-in-the-ai-era-google-at-msc-2026/) | [Google 2026 Responsible AI Report](https://blog.google/innovation-and-ai/products/responsible-ai-2026-report-ongoing-work/) | [GTIG AI Threat Tracker](https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/)

---

### Cybersecurity Tech Predictions for 2026: Zero Trust, PQC, AI Defense

The Hacker News published an industry-consensus piece on what 2026 looks like from a technology perspective:

- **AI defense** overtaking reactive SIEM/SOAR as the new baseline
- **Zero Trust identity** for non-human actors (agents, APIs, bots) as the #1 enterprise priority
- **Post-quantum cryptography (PQC)** migration deadlines forcing real budget conversations
- **Lifecycle security** â€” baking security into AI model development, not bolting it on after deployment

The common thread: AI is forcing security to think in systems, not products.

ðŸ”— [The Hacker News: Cybersecurity Predictions 2026](https://thehackernews.com/2026/02/cybersecurity-tech-predictions-for-2026.html)

---

## ðŸ› ï¸ Tools & Research

### Wiz: AI Cyber Model Arena â€” 257-Challenge Benchmark

Wiz launched the **AI Cyber Model Arena**, a real-world benchmark suite of **257 challenges** across five offensive security domains:

- Zero-day discovery
- CVE (code vulnerability) detection  
- API security
- Web security
- Cloud security

The goal: objectively evaluate how well AI agents perform on real offensive security tasks, enabling apples-to-apples comparison of models for security use cases.

ðŸ”— [Wiz Blog: AI Cyber Model Arena](https://www.wiz.io/blog/introducing-ai-cyber-model-arena-a-real-world-benchmark-for-ai-agents-in-cybersec)

### React2Shell: LLM-Generated Malware in the Wild

Darktrace researchers documented a case where hackers **used LLMs to create React2Shell malware** for cryptocurrency mining â€” exploiting a React2Shell vulnerability with AI-generated exploit code. The malware was functional and deployed in the wild, representing one of the clearest documented cases of AI-generated threat code moving from capability to production attack.

ðŸ”— [Security Boulevard: React2Shell](https://securityboulevard.com/2026/02/hackers-use-llm-to-create-react2shell-malware-the-latest-example-of-ai-generated-threat/)

---

## ðŸ“– Long Reads Worth Your Time

- **[Prompt Injection Attacks: Complete Technical Guide 2026](https://www.hackernoob.tips/prompt-injection-attacks-against-llm-agents-the-complete-technical-guide-for-2026/)** â€” Johann Rehberger's thesis: "Prompt injection cannot be fixed." Comprehensive taxonomy + practical mitigations. Required reading for anyone building agentic systems.
- **[Zero-Trust Architecture for AI Agents 2026](https://www.hackernoob.tips/securing-ai-agent-infrastructure-a-zero-trust-architecture-guide-for-2026/)** â€” "When AI Can Execute Code, Every Injection Is an RCE." Real-world CVE breakdowns and defense strategies.
- **[LLM Security Guide for CTOs (Medium)](https://medium.com/@pr_7329/llm-security-guide-for-ctos-and-it-security-officers-working-on-ai-projects-in-2026-2e13f7a78ff7)** â€” Passive vulnerability scanning is dead. Active AI red teaming is the new baseline.
- **[ZDNET: 4 Critical AI Vulnerabilities Exploited Faster Than Defenders Can Respond](https://www.zdnet.com/article/ai-security-threats-2026-overview/)** â€” Good survey of the current exploitation velocity gap.
- **[MIT Tech Review: AI Already Making Online Crimes Easier](https://www.technologyreview.com/2026/02/12/1132386/ai-already-making-online-swindles-easier/)** â€” LLM-powered ransomware: not theoretical, documented in the wild.

---

## ðŸ“Š Stat of the Week

> **128 million** â€” Combined installs of four VS Code extensions with unpatched critical vulnerabilities disclosed this week.
> The developer tools supply chain is the new enterprise attack surface. One malicious extension. One unpatched CVE. Entire org compromised.

---

## ðŸ´ Red Team Corner

### AI C2 Proxy: What Detection Looks Like

The Check Point "AI as a C2 Proxy" technique bypasses most traditional network controls. What defenders *can* do:

| Detection Layer | What to Look For |
|----------------|------------------|
| Network (CASB) | Abnormal query volume to Copilot/Grok from non-user processes |
| Endpoint (EDR) | Process trees where AI API calls originate from non-browser binaries |
| Behavioral | Correlation between AI assistant queries and outbound data transfer patterns |
| Identity | AI assistant sessions authenticated by service accounts, not users |

> **Bottom line:** Allow-listing AI domains while ignoring behavioral signals is the equivalent of allowing HTTPS because "it's encrypted." The domain isn't the threat. The behavior is.

---

*Next issue: Thursday, February 26.*
*Tips, CVEs, or tools to feature? Drop them in the research vault.*

---
**Issue #8 | AI Security Weekly | February 2026**
