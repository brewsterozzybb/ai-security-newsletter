# ðŸ›¡ï¸ AI Security Weekly â€” Issue #9
**Friday, February 20, 2026**

> *Covering the intersection of AI systems and security: vulnerabilities, tooling, research, and the arms race nobody asked for.*

---

## ðŸ”¥ This Week's Top Story

### PromptSpy: The First Android Malware to Use Generative AI at Runtime

ESET researchers disclosed **PromptSpy**, a landmark find: the **first known Android malware to integrate generative AI as a live component of its runtime operation**. Discovered in February 2026, PromptSpy abuses Google's **Gemini AI chatbot** â€” not as a development tool, but as an active decision-making engine while the malware is running on a victim's device.

Here's what makes it notable: PromptSpy hard-codes a Gemini prompt and API key inside the malware itself. It assigns Gemini the persona of an "Android automation assistant," then sends it an XML dump of the current device screen. Gemini analyzes the UI and responds with JSON instructions â€” exactly where to tap, what to press â€” to keep the malicious app pinned in Android's recent apps list, preventing it from being killed by the user or OS.

This is the loop: **malware â†’ screenshot â†’ Gemini â†’ tap instruction â†’ malware continues**. Because it reasons about UI in real time, it can adapt to any Android version, OEM skin, or layout â€” dramatically widening its potential victim pool.

Beyond persistence, PromptSpy's core payload is a built-in VNC module granting full remote access. Its other capabilities:
- Lockscreen PIN/password interception
- Screen recording and on-demand screenshots
- Blocking uninstallation via Android accessibility service overlays

The campaign appears financially motivated, targeting users in Argentina. C2 server: `54.67.2[.]84` via VNC protocol.

> **Why it matters:** The leap from "AI helps write malware" to "AI runs inside malware" happened faster than most threat models assumed. Every Android malware that follows can now copy this template â€” real-time AI reasoning as a persistence primitive is now in the wild.

ðŸ”— [The Hacker News](https://thehackernews.com/2026/02/promptspy-android-malware-abuses-google.html) | [BleepingComputer](https://www.bleepingcomputer.com/news/security/promptspy-is-the-first-known-android-malware-to-use-generative-ai-at-runtime/) | [ESET WeLiveSecurity](https://www.welivesecurity.com/en/eset-research/promptspy-ushers-in-era-android-threats-using-genai/) | [SecurityWeek](https://www.securityweek.com/promptspy-android-malware-abuses-gemini-ai-at-runtime-for-persistence/)

---

## ðŸ§¨ Vulnerability Roundup

### Microsoft Copilot Bug Exposed Confidential Customer Emails for Weeks

Microsoft confirmed a significant bug in **Microsoft 365 Copilot**: the AI assistant was **reading and summarizing confidential customer emails** â€” emails that data-protection policies explicitly restricted â€” for approximately a month before a patch was deployed.

The bug allowed Copilot's "Chat" feature to bypass organizational sensitivity labels and access protected communications. Affected customers may not know what was ingested.

> **Key question nobody's answered:** How many Copilot summaries of protected emails were stored, shared, or retained by Microsoft infrastructure? The patch stops the leak â€” the audit trail doesn't.

ðŸ”— [TechCrunch](https://techcrunch.com/2026/02/18/microsoft-says-office-bug-exposed-customers-confidential-emails-to-copilot-ai/) | [Windows Central](https://www.windowscentral.com/artificial-intelligence/microsoft-copilot/microsoft-365-copilot-ai-summarizing-confidential-emails) | [WinBuzzer](https://winbuzzer.com/2026/02/19/microsoft-copilot-bug-exposed-confidential-emails-xcxwbn/) | [BBC](https://www.bbc.co.uk/news/articles/c8jxevd8mdyo)

---

### CVE-2026-26030 â€” Microsoft Semantic Kernel Python SDK: RCE (CVSS 9.9)

A critical remote code execution vulnerability was disclosed in **Microsoft's Semantic Kernel Python SDK** (versions prior to 1.39.4), specifically in the `InMemoryVectorStore` filter functionality. CVSS score: **9.9**.

Semantic Kernel is Microsoft's primary SDK for building LLM-powered agentic applications. An attacker exploiting this vulnerability could execute arbitrary code in the context of any application built on the SDK â€” which includes a growing percentage of enterprise AI tooling.

**Action:** Patch to `semantic-kernel >= 1.39.4` immediately.

ðŸ”— [GitLab Advisory (CVE-2026-26030)](https://advisories.gitlab.com/pkg/pypi/semantic-kernel/CVE-2026-26030/) | [TheHackerWire](https://www.thehackerwire.com/vulnerability/CVE-2026-26030/)

---

### Speed Round: Other Critical CVEs This Week

| CVE | Component | CVSS | Impact |
|-----|-----------|------|--------|
| CVE-2025-12107 | Velocity Template Engine | 10.0 | RCE |
| CVE-2026-26339 | Hyland Alfresco Transformation Service | 9.8 | RCE |
| CVE-2026-25242 | Gogs Self-Hosted Git | 9.8 | Unauthenticated access |
| CVE-2026-27476 | RustFly 2.0.0 | 9.8 | Command injection |

ðŸ”— [TheHackerWire CVE Feed](https://www.thehackerwire.com/)

---

## ðŸŽ¯ Attacks & Research

### CISA Partially Offline: DHS Shutdown Creates National Cybersecurity Blind Spots

A **partial DHS shutdown** â€” ongoing since February 14, 2026 â€” has significantly degraded **CISA's operational capacity**. With portions of the agency's workforce furloughed or constrained, CISA's ability to coordinate incident response, issue advisories, and monitor critical infrastructure has been reduced at exactly the wrong moment: a week in which multiple critical CVEs and novel malware have been disclosed simultaneously.

> **The compound risk:** CISA weakening + novel AI malware + critical agentic AI vulnerabilities = a window adversaries will notice.

---

### Microsoft OAuth Campaign: Persistent Token Theft Targeting M365

An **ongoing campaign** is targeting **Microsoft 365** environments to steal OAuth tokens and establish long-term persistent access. Victims are being compromised through crafted OAuth flows that, once authorized, hand attackers durable access without requiring further credential theft.

OAuth token theft is increasingly the preferred persistence technique for cloud-native attackers â€” it survives password resets, MFA changes, and most traditional remediation playbooks.

ðŸ”— [IT Security News](https://www.itsecuritynews.info/it-security-news-hourly-summary-2026-02-20-03h-2-posts/)

---

### Persona (Peter Thiel-Funded): Biometric Data Sharing With Governments Alleged

Cybersecurity researchers allege that **Persona**, a widely-used age verification and identity service (Peter Thiel-funded), has been:
- Retaining user biometrics and government-issued photo IDs for **three years**
- Sharing user data with **US and Canadian federal agencies**

Persona's KYC services are embedded in hundreds of platforms. The allegations raise significant questions about whether users consented to government data sharing when submitting ID documents for age verification.

ðŸ”— [PiunikaWeb](https://piunikaweb.com/2026/02/19/persona-age-verification-surveillance-allegations/)

---

## ðŸ“Š Industry Reports

### Cisco State of AI Security 2026: "The Connective Tissue Is Broken"

Cisco released their **State of AI Security 2026** annual report today, and the headline finding is structural: the **Model Context Protocol (MCP)** and other agent-to-tool communication layers have *"created a vast and often unmonitored attack surface."*

Key findings:
- **83% of organizations** planned to deploy agentic AI â€” only **29% felt ready** to do it securely
- Open-weight models remain broadly susceptible to jailbreaks and prompt injection, **particularly over multi-turn conversations** â€” Cisco's phrase: *"death by a thousand prompts"*
- AI supply chains (datasets, open-source components, APIs) lack adequate security governance
- The speed of AI adoption has bypassed traditional security vetting, creating systemic exposure in production workflows

> **Cisco's framing:** This isn't an upgrade problem. It's a paradigm shift. The security approaches built for software don't map cleanly onto agentic AI systems that reason, decide, and act autonomously.

ðŸ”— [Cisco Blog](https://blogs.cisco.com/ai/cisco-state-of-ai-security-2026-report) | [Cybersecurity Dive](https://www.cybersecuritydive.com/news/ai-agents-model-context-protocol-cisco-report/812580/) | [Full Report](https://learn-cloudsecurity.cisco.com/2026-state-of-ai-security-report)

---

### Google Threat Intelligence: AI Models Are Now High-Value Targets

Google's threat intelligence team warned that AI models have shifted from tools to **primary attack targets** in 2026. The primary technique: **"distillation attacks"** â€” reverse-engineering proprietary models through massive, systematic API prompting to extract training data, architectures, and capabilities without authorization.

The attack is economically rational: stealing a trained model is cheaper than training one. Expect distillation attacks to scale alongside commercial model value.

ðŸ”— [Android Headlines](https://www.androidheadlines.com/2026/02/ai-cybersecurity-threat-intelligence-extraction-attacks-google-report-2026.html)

---

## ðŸ› ï¸ Tools & Tooling

### SOC Prime DetectFlow OSS: Pre-SIEM AI Detection Orchestration

SOC Prime released **DetectFlow** as open-source â€” a Flink-based detection orchestration layer that applies **Sigma rules to streaming log events before they hit your SIEM**, tagging matched events with MITRE ATT&CK metadata in real time.

Performance claims:
- *"Sub-second MTTD: 0.005â€“0.01 seconds vs 15+ minutes for SIEM"*
- *"10x rule capacity on existing infrastructure"*

Notable capabilities: rule hot-reload (no downtime for rule updates), Kafka topic sync, pre-filters to reduce false positives, and support for rule sources from SOC Prime Platform, GitHub repos, or local repos.

Stack: Flink + Kafka + PostgreSQL, Kubernetes deployment via Flink Kubernetes Operator + Helm.

License: EU Public License v1.2 or SOC Prime Commercial License.

ðŸ”— [GitHub: socprime/detectflow-main](https://github.com/socprime/detectflow-main)

---

### Karpathy's "LLM Council": Multi-Model Consensus Experiments

Andrej Karpathy shipped a simple open-source web app â€” **LLM Council** â€” that lets you query multiple models simultaneously via OpenRouter, have them critique each other's answers anonymously, and synthesize a final response via a designated "Chairman" model.

It's a weekend hack (Karpathy's words: *"99% vibe coded"*), not a supported product, but the pattern is instructive for anyone evaluating AI responses where model-specific biases matter.

Stack: FastAPI + React/Vite. Config: edit `backend/config.py` to choose council members and Chairman.

ðŸ”— [GitHub (Karpathy)](https://github.com/karpathy/llm_council)

---

### Security Compass: Policy-Driven Security for Agentic AI Pipelines

Security Compass released **SD Elements for Agentic AI Workflow**, adding policy-driven security and compliance tracking directly into AI development pipelines. Aimed at teams embedding AI agents into SDLC tooling who need audit trails and compliance posture visibility.

ðŸ”— [Help Net Security](https://www.helpnetsecurity.com/2026/02/20/security-compass-sd-elements-for-agentic-ai-workflow/)

---

## ðŸ“– Long Reads Worth Your Time

- **[Cisco State of AI Security 2026 (Full Report)](https://learn-cloudsecurity.cisco.com/2026-state-of-ai-security-report)** â€” The definitive 2026 survey of AI threat intelligence, policy, and research. Required reading.
- **[ESET: PromptSpy Technical Writeup](https://www.welivesecurity.com/en/eset-research/promptspy-ushers-in-era-android-threats-using-genai/)** â€” Deep technical breakdown of the Gemini-powered persistence mechanism.
- **[Red Canary: Intelligence Insights February 2026](https://redcanary.com/blog/threat-intelligence/intelligence-insights-february-2026/)** â€” ClearFake evolution: initial access techniques shifting from `mshta.exe` to `SyncAppvPublishingServer.vbs` in January 2026.
- **[FIRST: 50,000+ CVEs Forecast for 2026](https://www.infosecurity-magazine.com/news/first-forecasts-record-50000-cve)** â€” Median estimate of 59,427 CVEs for 2026 (90% CI: 30Kâ€“117K). The math on patching doesn't work anymore.

---

## ðŸ“Š Stat of the Week

> **9.9 / 10.0** â€” CVSS score for CVE-2026-26030 in Microsoft's Semantic Kernel Python SDK.
> The framework powering enterprise AI agents has a near-maximum-severity RCE. If you're building on Semantic Kernel and haven't patched to 1.39.4, you're running vulnerable AI infrastructure.

---

## ðŸ´ Red Team Corner

### PromptSpy Defense: What It Looks Like in Practice

PromptSpy's Gemini-powered persistence is novel, but it has detectable characteristics:

| Detection Layer | Signal |
|----------------|--------|
| Mobile MDM/EDR | Accessibility service abuse by non-system apps; VNC traffic to non-corporate endpoints |
| Network | Gemini API calls (`generativelanguage.googleapis.com`) from unexpected processes; VNC to `54.67.2[.]84` |
| App Audit | Apps requesting accessibility + screen recording + network simultaneously |
| Behavioral | Repeated lockscreen interaction attempts not attributable to user input |

> **The defense paradox:** Gemini's API is Google-signed traffic. Organizations can't block it wholesale without breaking legitimate Gemini use. Behavioral correlation is the only path â€” and most mobile MDM tools aren't built for it yet.

---

*Next issue: Thursday, February 26.*
*Tips, CVEs, or tools to feature? Drop them in the research vault.*

---
**Issue #9 | AI Security Weekly | February 2026**
